{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import json_lines\n",
    "import codecs\n",
    "from keras_bert import load_trained_model_from_checkpoint, Tokenizer\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from keras.layers import *\n",
    "from keras.optimizers import Adam\n",
    "from keras.models import Model\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrained_path = 'pretrained/uncased_L-12_H-768_A-12'\n",
    "config_path = os.path.join(pretrained_path, 'bert_config.json')\n",
    "checkpoint_path = os.path.join(pretrained_path, 'bert_model.ckpt')\n",
    "vocab_path = os.path.join(pretrained_path, 'vocab.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEQ_LEN = 128\n",
    "BATCH_SIZE = 25\n",
    "EPOCHS = 5\n",
    "LR = 5e-6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_model = load_trained_model_from_checkpoint(\n",
    "    config_path,\n",
    "    checkpoint_path,\n",
    "    training=True,\n",
    "    trainable=True,\n",
    "    seq_len=SEQ_LEN,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Tokeniser(Tokenizer):\n",
    "    def __init__(self, dict_path):\n",
    "        token_dict = {}\n",
    "        with codecs.open(dict_path, 'r', 'utf8') as reader:\n",
    "            for line in reader:\n",
    "                token = line.strip()\n",
    "                token_dict[token] = len(token_dict)\n",
    "        super().__init__(token_dict)\n",
    "\n",
    "def load_data(tokenizer: Tokeniser, file_path,\n",
    "    text_label='trans_en', target_label='voted_up', max_len=100, batch_size=20):\n",
    "    indices, sentiments = [], []\n",
    "    with open(file_path, 'rb') as f:\n",
    "        for item in json_lines.reader(f):\n",
    "            ids, segments = tokenizer.encode(item[text_label].lower(), max_len=max_len)\n",
    "            indices.append(ids)\n",
    "            sentiments.append(int(item[target_label]))\n",
    "    items = list(zip(indices, sentiments))\n",
    "    np.random.shuffle(items)\n",
    "    indices, sentiments = zip(*items)\n",
    "    indices = np.array(indices)\n",
    "    mod = indices.shape[0] % batch_size\n",
    "    if mod > 0:\n",
    "        indices, sentiments = indices[:-mod], sentiments[:-mod]\n",
    "    return indices, np.array(sentiments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model():\n",
    "    inputs = bert_model.inputs[:2]\n",
    "    dense = bert_model.get_layer('NSP-Dense').output\n",
    "    outputs = Dense(units=2, activation='softmax')(dense)\n",
    "\n",
    "    model = Model(inputs, outputs)\n",
    "    model.compile(\n",
    "        optimizer=Adam(LR),\n",
    "        loss='sparse_categorical_crossentropy',\n",
    "        metrics=['sparse_categorical_accuracy'],\n",
    "    )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokeniser = Tokeniser(vocab_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_train(model, target_label='voted_up', model_name='bert_voted_up'):\n",
    "    tokenizer = Tokenizer(paths.vocab)\n",
    "    X, y = load_data(tokeniser, 'data/reviews_112_trans-en.jl',\n",
    "        target_label=target_label, max_len=SEQ_LEN, batch_size=BATCH_SIZE)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=42)\n",
    "    mcp_save = ModelCheckpoint(\"result/\"+MODEL_NAME+'.best.h5',\n",
    "        save_best_only=True, monitor='val_sparse_categorical_accuracy', mode='max')\n",
    "    model.fit(\n",
    "        [X_train, np.zeros_like(X_train)],\n",
    "        y_train,\n",
    "        epochs=EPOCHS,\n",
    "        validation_split=0.1,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        callbacks=[EarlyStopping(monitor='val_loss', patience=4), mcp_save]\n",
    "    )\n",
    "    model.save_weights(\"result/\"+model_name+\".h5\")"
   ]
  },
  {
   "source": [
    "# BERT Voted up"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = get_model()\n",
    "model_train(model, 'voted_up', 'bert_voted_up')"
   ]
  },
  {
   "source": [
    "Evaluation"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from sklearn.metrics import roc_auc_score, roc_curve, confusion_matrix, accuracy_score\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_roc(pred, y):\n",
    "    fpr, tpr, thresholds = roc_curve(y, pred)\n",
    "    try:\n",
    "        auc = roc_auc_score(y, pred)\n",
    "    except ValueError:\n",
    "        auc = \"undefined\"\n",
    "\n",
    "    fig, ax = plt.subplots(1, figsize=(8,8))\n",
    "    ax.plot(fpr, tpr, color='red')\n",
    "    ax.plot([0,1], [0,1], color='black', linestyle='--')\n",
    "    ax.set_title(f\"AUC: {auc}\")\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights(\"result/bert_voted_up.best.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = model.predict(get_X_array(X), verbose=True, batch_size=BATCH_SIZE)\n",
    "result_max = preds.argmax(axis=-1)\n",
    "tn, fp, fn, tp = confusion_matrix(y, result_max).ravel()\n",
    "\n",
    "print('Confusion matrix:')\n",
    "print('[{}, {}]'.format(tp, fp))\n",
    "print('[{}, {}]'.format(fn, tn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Accuracy: %.4f' % accuracy_score(y, result_max))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_roc(preds[:,1], y)"
   ]
  },
  {
   "source": [
    "# BERT Early access\n",
    "\n",
    "Training process"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = get_model()\n",
    "model_train(model, 'early_access', 'bert_early_access')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights(\"result/bert_early_access.best.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = model.predict(get_X_array(X), verbose=True, batch_size=BATCH_SIZE)\n",
    "result_max = preds.argmax(axis=-1)\n",
    "tn, fp, fn, tp = confusion_matrix(y, result_max).ravel()\n",
    "\n",
    "print('Confusion matrix:')\n",
    "print('[{}, {}]'.format(tp, fp))\n",
    "print('[{}, {}]'.format(fn, tn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Accuracy: %.4f' % accuracy_score(y, result_max))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_roc(preds[:,1], y)"
   ]
  }
 ]
}